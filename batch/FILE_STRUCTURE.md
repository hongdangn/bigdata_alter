# ğŸ“ CÃC FILE QUAN TRá»ŒNG TRONG PROJECT

## ğŸ¯ SCRIPTS Tá»° Äá»˜NG (Khuyáº¿n nghá»‹ dÃ¹ng)

| File | MÃ´ táº£ | Khi nÃ o dÃ¹ng |
|------|-------|--------------|
| **START_PIPELINE.bat** | ğŸš€ Cháº¡y táº¥t cáº£ pipeline 1 láº§n | Láº§n Ä‘áº§u setup, hoáº·c muá»‘n cháº¡y nhanh |
| **1_start_services.bat** | Khá»Ÿi Ä‘á»™ng Docker services | Báº¯t Ä‘áº§u session má»›i |
| **2_start_crawler.bat** | Báº­t crawler (Terminal 1) | Crawl data tá»« web |
| **3_start_kafka_to_minio.bat** | Báº­t Kafkaâ†’MinIO (Terminal 2) | LÆ°u data vÃ o data lake |
| **4_run_etl_batch.bat** | Cháº¡y ETL batch (Bronzeâ†’Silverâ†’Gold) | Sau khi cÃ³ Ä‘á»§ data |
| **5_view_results.bat** | Xem káº¿t quáº£ ETL | Xem data sau ETL |
| **9_stop_all.bat** | Dá»«ng táº¥t cáº£ services | Khi xong hoáº·c muá»‘n táº¯t mÃ¡y |

---

## ğŸ“– TÃ€I LIá»†U HÆ¯á»šNG DáºªN

| File | Ná»™i dung |
|------|----------|
| **QUICK_START.md** | ğŸš€ HÆ°á»›ng dáº«n nhanh cho ngÆ°á»i má»›i |
| **RUN_PIPELINE.md** | ğŸ“š HÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c |
| **ETL_GUIDE.md** | Kiáº¿n trÃºc Medallion (Bronze/Silver/Gold) |
| **MINIO_SETUP.md** | Setup MinIO data lake |
| **CRAWLER_GUIDE.md** | HÆ°á»›ng dáº«n crawler Scrapy |
| **SCHEDULING_GUIDE.md** | Láº­p lá»‹ch tá»± Ä‘á»™ng |

---

## ğŸ PYTHON SCRIPTS CHÃNH

### 1. Thu tháº­p dá»¯ liá»‡u (Crawling)
| File | Chá»©c nÄƒng |
|------|-----------|
| `run_continuous_crawler.py` | Crawler liÃªn tá»¥c nhiá»u tá»‰nh |
| `run_multi_province.py` | Crawler tuáº§n tá»± cÃ¡c tá»‰nh |
| `bds/batdongsan/spiders/bds_spider.py` | Scrapy spider chÃ­nh |

### 2. Data Pipeline
| File | Chá»©c nÄƒng |
|------|-----------|
| `kafka_to_minio.py` | ğŸ“¦ Kafka â†’ MinIO (Bronze layer) |
| `spark_streaming.py` | âš¡ Spark Streaming (real-time) |
| `etl_batch_job.py` | ğŸ¯ **ETL BATCH CHÃNH** (Bronzeâ†’Silverâ†’Gold) |
| `etl_scheduler.py` | ğŸ“… Láº­p lá»‹ch ETL tá»± Ä‘á»™ng |

### 3. Tiá»‡n Ã­ch
| File | Chá»©c nÄƒng |
|------|-----------|
| `view_results.py` | ğŸ‘ï¸ Xem káº¿t quáº£ ETL |
| `monitor.py` | ğŸ“Š GiÃ¡m sÃ¡t pipeline |
| `pre_process.py` | ğŸ§¹ Xá»­ lÃ½ text tiáº¿ng Viá»‡t |
| `utils.py` | ğŸ”§ HÃ m tiá»‡n Ã­ch chung |

---

## âš™ï¸ Cáº¤U HÃŒNH

| File | MÃ´ táº£ |
|------|-------|
| `docker-compose.yml` | ğŸ³ Cáº¥u hÃ¬nh Kafka, MinIO, ES, Kibana |
| `requirements.txt` | ğŸ“¦ Python dependencies |
| `.env` | ğŸ” Biáº¿n mÃ´i trÆ°á»ng (náº¿u cÃ³) |
| `bds/scrapy.cfg` | Cáº¥u hÃ¬nh Scrapy project |
| `bds/batdongsan/settings.py` | Settings Scrapy spider |
| `bds/batdongsan/pipelines.py` | Pipeline gá»­i Kafka |

---

## ğŸ—‚ï¸ Cáº¤U TRÃšC THá»¨ Má»¤C

```
bigdata_alter/
â”œâ”€â”€ ğŸ“ bds/                          # Scrapy project
â”‚   â”œâ”€â”€ scrapy.cfg
â”‚   â”œâ”€â”€ run_crawler.sh
â”‚   â””â”€â”€ batdongsan/
â”‚       â”œâ”€â”€ spiders/
â”‚       â”‚   â””â”€â”€ bds_spider.py        # Spider chÃ­nh
â”‚       â”œâ”€â”€ pipelines.py             # Kafka pipeline
â”‚       â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ ğŸ¯ SCRIPTS CHáº Y PIPELINE
â”‚   â”œâ”€â”€ START_PIPELINE.bat           # â­ Cháº¡y táº¥t cáº£ 1 láº§n
â”‚   â”œâ”€â”€ 1_start_services.bat
â”‚   â”œâ”€â”€ 2_start_crawler.bat
â”‚   â”œâ”€â”€ 3_start_kafka_to_minio.bat
â”‚   â”œâ”€â”€ 4_run_etl_batch.bat
â”‚   â”œâ”€â”€ 5_view_results.bat
â”‚   â””â”€â”€ 9_stop_all.bat
â”‚
â”œâ”€â”€ ğŸ“š TÃ€I LIá»†U
â”‚   â”œâ”€â”€ QUICK_START.md               # â­ Báº¯t Ä‘áº§u tá»« Ä‘Ã¢y
â”‚   â”œâ”€â”€ RUN_PIPELINE.md              # HÆ°á»›ng dáº«n chi tiáº¿t
â”‚   â”œâ”€â”€ ETL_GUIDE.md
â”‚   â”œâ”€â”€ MINIO_SETUP.md
â”‚   â”œâ”€â”€ CRAWLER_GUIDE.md
â”‚   â””â”€â”€ SCHEDULING_GUIDE.md
â”‚
â”œâ”€â”€ ğŸ PYTHON SCRIPTS
â”‚   â”œâ”€â”€ run_continuous_crawler.py    # Crawler liÃªn tá»¥c
â”‚   â”œâ”€â”€ run_multi_province.py        # Crawler nhiá»u tá»‰nh
â”‚   â”œâ”€â”€ kafka_to_minio.py            # Kafka â†’ MinIO
â”‚   â”œâ”€â”€ spark_streaming.py           # Spark Streaming
â”‚   â”œâ”€â”€ etl_batch_job.py             # â­ ETL BATCH CHÃNH
â”‚   â”œâ”€â”€ etl_scheduler.py             # Scheduler
â”‚   â”œâ”€â”€ view_results.py              # Xem káº¿t quáº£
â”‚   â”œâ”€â”€ monitor.py
â”‚   â”œâ”€â”€ pre_process.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ âš™ï¸ Cáº¤U HÃŒNH
â”‚   â”œâ”€â”€ docker-compose.yml           # Docker services
â”‚   â”œâ”€â”€ requirements.txt             # Python deps
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ ğŸ“‚ bigdata/                      # Python virtualenv
    â””â”€â”€ ...
```

---

## ğŸ¯ Lá»˜ TRÃŒNH Há»ŒC Táº¬P

### 1ï¸âƒ£ NgÆ°á»i má»›i báº¯t Ä‘áº§u
```
1. Äá»c: QUICK_START.md
2. Cháº¡y: START_PIPELINE.bat
3. Äá»£i 1-2 giá»
4. Cháº¡y: 4_run_etl_batch.bat
5. Cháº¡y: 5_view_results.bat
```

### 2ï¸âƒ£ Hiá»ƒu rÃµ tá»«ng bÆ°á»›c
```
1. Äá»c: RUN_PIPELINE.md
2. Cháº¡y tá»«ng script thá»§ cÃ´ng:
   - 1_start_services.bat
   - 2_start_crawler.bat
   - 3_start_kafka_to_minio.bat
   - 4_run_etl_batch.bat
3. Xem code trong tá»«ng .py file
4. Äá»c: ETL_GUIDE.md Ä‘á»ƒ hiá»ƒu Medallion Architecture
```

### 3ï¸âƒ£ NÃ¢ng cao - Custom pipeline
```
1. Äá»c code: etl_batch_job.py
2. Hiá»ƒu logic: Bronze â†’ Silver â†’ Gold
3. Thay Ä‘á»•i transformation logic
4. Äá»c: SCHEDULING_GUIDE.md Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a
5. Deploy production
```

---

## ğŸš€ CÃCH DÃ™NG NHANH NHáº¤T

### Láº§n Ä‘áº§u cháº¡y
```bash
# 1. Double-click:
START_PIPELINE.bat

# 2. Äá»£i 1-2 giá» (xem MinIO: http://localhost:9001)

# 3. Double-click:
4_run_etl_batch.bat

# 4. Double-click:
5_view_results.bat
```

### Láº§n sau (Ä‘Ã£ cÃ³ data)
```bash
# 1. Khá»Ÿi Ä‘á»™ng services
1_start_services.bat

# 2. Cháº¡y ETL
4_run_etl_batch.bat

# 3. Xem káº¿t quáº£
5_view_results.bat
```

---

## â“ CÃ‚U Há»I THÆ¯á»œNG Gáº¶P

### Q: File nÃ o cháº¡y Ä‘áº§u tiÃªn?
**A:** `START_PIPELINE.bat` hoáº·c Ä‘á»c `QUICK_START.md`

### Q: ETL batch á»Ÿ Ä‘Ã¢u?
**A:** `etl_batch_job.py` - cháº¡y báº±ng `4_run_etl_batch.bat`

### Q: Xem dá»¯ liá»‡u á»Ÿ Ä‘Ã¢u?
**A:** 
- MinIO Console: http://localhost:9001
- Hoáº·c cháº¡y: `5_view_results.bat`

### Q: Lá»—i "Docker not running"?
**A:** Má»Ÿ Docker Desktop trÆ°á»›c khi cháº¡y

### Q: Crawl bao lÃ¢u?
**A:** Tá»‘i thiá»ƒu 1-2 giá» Ä‘á»ƒ cÃ³ Ä‘á»§ data demo

### Q: Data lÆ°u á»Ÿ Ä‘Ã¢u?
**A:** 
- Docker volume: MinIO data
- Thá»±c táº¿: `D:\minio\data\datalake\`

---

## ğŸ“ SUPPORT

Náº¿u gáº·p lá»—i, kiá»ƒm tra:
1. Docker Desktop Ä‘Ã£ cháº¡y chÆ°a
2. `docker ps` - Xem containers
3. Logs trong cÃ¡c terminal
4. File log: `crawler.log`, `minio.log`

---

## ğŸ‰ HAPPY CODING!

Project nÃ y implement **Medallion Architecture** vá»›i:
- ğŸ¥‰ **Bronze:** Raw data tá»« Kafka
- ğŸ¥ˆ **Silver:** Cleaned, deduplicated, standardized
- ğŸ¥‡ **Gold:** Analytics, aggregations, metrics

Powered by: Scrapy + Kafka + MinIO + PySpark ğŸš€
