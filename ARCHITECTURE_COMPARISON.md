# ğŸ”„ Architecture Comparison: Streaming vs Batch vs Hybrid

## ğŸ“Š Kiáº¿n trÃºc Lambda Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DATA SOURCE LAYER     â”‚
                    â”‚   (Scrapy Crawler)      â”‚
                    â”‚   - bds.com.vn          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
                â”ƒ                              â”ƒ
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SPEED LAYER        â”‚      â”‚   BATCH LAYER        â”‚
    â”‚   (Real-time)        â”‚      â”‚   (Historical)       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ Kafka Queue        â”‚      â”‚ â€¢ JSON/CSV Files     â”‚
    â”‚ â€¢ Spark Streaming    â”‚      â”‚ â€¢ Spark Batch        â”‚
    â”‚ â€¢ < 1s latency       â”‚      â”‚ â€¢ Scheduler          â”‚
    â”‚ â€¢ Continuous         â”‚      â”‚ â€¢ On-demand/Cron     â”‚
    â”‚                      â”‚      â”‚ â€¢ Aggregations       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   SERVING LAYER          â”‚
                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                â”‚ â€¢ Elasticsearch (Search) â”‚
                â”‚ â€¢ Kibana (Visualization) â”‚
                â”‚ â€¢ Parquet (Data Lake)    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ So sÃ¡nh 3 Architecture Modes

### **Mode 1: Pure Streaming (Hiá»‡n táº¡i)**

```
Scrapy â†’ Kafka â†’ Spark Streaming â†’ Elasticsearch â†’ Kibana
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Latency tháº¥p (< 1 giÃ¢y)
- âœ… Real-time monitoring
- âœ… PhÃ¹ há»£p cho alerts, dashboards

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ KhÃ³ lÃ m complex aggregations
- âŒ KhÃ´ng xá»­ lÃ½ historical data tá»‘t
- âŒ Pháº£i running 24/7

**Use cases:**
- Real-time price monitoring
- Instant search updates
- Live dashboard

---

### **Mode 2: Pure Batch**

```
Scrapy â†’ Files â†’ Spark Batch â†’ Elasticsearch/Parquet
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Complex analytics dá»… dÃ ng
- âœ… Xá»­ lÃ½ historical data hiá»‡u quáº£
- âœ… Resource-efficient (chá»‰ cháº¡y khi cáº§n)
- âœ… CÃ³ thá»ƒ reprocess data

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Latency cao (phÃºt â†’ giá»)
- âŒ KhÃ´ng real-time

**Use cases:**
- Daily/weekly reports
- Historical trend analysis
- ML model training
- Data warehouse updates

---

### **Mode 3: Hybrid (Lambda Architecture) â­ RECOMMENDED**

```
              Scrapy
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼
     Kafka            Files
        â–¼               â–¼
   Streaming         Batch
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
         Elasticsearch
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Best of both worlds
- âœ… Real-time + historical analytics
- âœ… Flexible query patterns
- âœ… Data redundancy

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Complexity cao hÆ¡n
- âŒ Cáº§n maintain 2 pipelines

**Use cases:**
- Production systems
- Khi cáº§n cáº£ real-time vÃ  analytics
- Compliance requirements

---

## ğŸ“ File Structure Má»›i

```
bigdata_alter/
â”œâ”€â”€ spark_streaming.py          # Speed Layer (existing)
â”œâ”€â”€ spark_batch.py              # Batch Layer (NEW)
â”œâ”€â”€ batch_scheduler.py          # Scheduler (NEW)
â”œâ”€â”€ export_to_batch.py          # Batch Export Pipeline (NEW)
â”œâ”€â”€ unified_pipeline.py         # Unified Manager (NEW)
â”‚
â”œâ”€â”€ data/                       # (NEW)
â”‚   â”œâ”€â”€ batch_input/           # Raw batch files
â”‚   â””â”€â”€ processed_batch/       # Processed Parquet files
â”‚
â”œâ”€â”€ BATCH_PROCESSING_GUIDE.md  # Full guide (NEW)
â”œâ”€â”€ QUICKSTART_BATCH.md        # Quick start (NEW)
â”œâ”€â”€ setup_batch.bat            # Windows setup (NEW)
â””â”€â”€ setup_batch.sh             # Linux setup (NEW)
```

---

## ğŸš€ Quick Start for Each Mode

### **Streaming Only**
```bash
# Terminal 1
python spark_streaming.py

# Terminal 2
cd bds
scrapy crawl bds_spider
```

### **Batch Only**
```bash
# One-time run
python spark_batch.py

# Or scheduled
python batch_scheduler.py
```

### **Hybrid (Recommended)**
```bash
# Easy way
python unified_pipeline.py
# Choose option 4: "Start Both"

# Manual way
# Terminal 1: Streaming
python spark_streaming.py

# Terminal 2: Batch scheduler
python batch_scheduler.py

# Terminal 3: Crawler
cd bds
scrapy crawl bds_spider
```

---

## ğŸ“Š Data Flow Comparison

### **Streaming Flow**
```
1. Scrapy scrapes â†’ item
2. PushToKafka pipeline â†’ Kafka
3. Spark Streaming reads â†’ process
4. Write to Elasticsearch â†’ immediate
â±ï¸ Total: < 2 seconds
```

### **Batch Flow**
```
1. Scrapy scrapes â†’ item
2. ExportToBatchFile pipeline â†’ JSON file
3. [Wait until scheduled time or manual trigger]
4. Spark Batch reads â†’ process â†’ aggregate
5. Write to Elasticsearch + Parquet
â±ï¸ Total: Scheduled (e.g., daily)
```

### **Hybrid Flow**
```
1. Scrapy scrapes â†’ item
2. Split to:
   - PushToKafka â†’ Streaming â†’ ES (real-time)
   - ExportToBatchFile â†’ Files â†’ Batch â†’ ES + Parquet (scheduled)
3. Serving layer merges both views
â±ï¸ Real-time + Historical
```

---

## ğŸ¯ When to Use What?

| Requirement | Streaming | Batch | Hybrid |
|-------------|-----------|-------|--------|
| Real-time dashboard | âœ… | âŒ | âœ… |
| Daily reports | âŒ | âœ… | âœ… |
| Complex aggregations | âš ï¸ | âœ… | âœ… |
| Historical analysis | âŒ | âœ… | âœ… |
| Cost optimization | âŒ | âœ… | âš ï¸ |
| Data reprocessing | âŒ | âœ… | âœ… |
| Low latency | âœ… | âŒ | âœ… |
| Simpler maintenance | âœ… | âœ… | âŒ |

---

## ğŸ’¡ Recommended Scenarios

### **Scenario 1: Student Project / Demo**
â†’ **Use Streaming Only**
- ÄÆ¡n giáº£n, dá»… demo
- Real-time impressive cho presentation
- Ãt phá»©c táº¡p

### **Scenario 2: Production System**
â†’ **Use Hybrid**
- Reliable vá»›i data backup
- Flexible analytics
- Compliance ready

### **Scenario 3: Research / Analytics Focus**
â†’ **Use Batch**
- Focus vÃ o data quality
- Complex statistics
- ML model training

### **Scenario 4: Real Estate Agency App**
â†’ **Use Hybrid**
- Users cáº§n real-time search
- Business cáº§n daily reports
- Marketing cáº§n trend analysis

---

## ğŸ”§ Configuration Matrix

### **Scrapy Pipeline Config**

**Streaming only:**
```python
ITEM_PIPELINES = {
    'batdongsan.pipelines.BatdongsanPipeline': 300,
    'batdongsan.pipelines.PushToKafka': 400,
}
```

**Batch only:**
```python
ITEM_PIPELINES = {
    'batdongsan.pipelines.BatdongsanPipeline': 300,
    'export_to_batch.ExportToBatchFile': 500,
}
```

**Hybrid:**
```python
ITEM_PIPELINES = {
    'batdongsan.pipelines.BatdongsanPipeline': 300,
    'batdongsan.pipelines.PushToKafka': 400,
    'export_to_batch.ExportToBatchFile': 500,
}
```

---

## ğŸ“ˆ Performance Characteristics

### **Throughput**
- **Streaming:** ~1000 items/second
- **Batch:** ~10000 items/second (vá»›i optimization)

### **Latency**
- **Streaming:** < 1 second
- **Batch:** Minutes to hours (scheduled)

### **Resource Usage**
- **Streaming:** Continuous CPU/Memory
- **Batch:** Burst CPU/Memory, idle otherwise

### **Data Quality**
- **Streaming:** Basic validation
- **Batch:** Advanced validation + deduplication

---

## ğŸ“ Learning Path

**Beginner:** Start with Streaming
1. Understand the basic flow
2. See real-time updates in Kibana
3. Simple to debug

**Intermediate:** Add Batch
1. Learn Spark batch processing
2. Understand scheduling
3. Data lake concepts

**Advanced:** Implement Hybrid
1. Unified architecture
2. Handle both pipelines
3. Production-ready system

---

## ğŸ”— Next Steps

1. **Read guides:**
   - `BATCH_PROCESSING_GUIDE.md` - Chi tiáº¿t Ä‘áº§y Ä‘á»§
   - `QUICKSTART_BATCH.md` - Báº¯t Ä‘áº§u nhanh

2. **Run setup:**
   ```bash
   # Windows
   setup_batch.bat
   
   # Linux/macOS
   chmod +x setup_batch.sh
   ./setup_batch.sh
   ```

3. **Try unified manager:**
   ```bash
   python unified_pipeline.py
   ```

4. **Experiment:**
   - Cháº¡y tá»«ng mode
   - So sÃ¡nh performance
   - Chá»n phÃ¹ há»£p vá»›i use case cá»§a báº¡n

---

## ğŸ“ Troubleshooting

**Q: NÃªn chá»n mode nÃ o?**
A: Náº¿u há»c â†’ Streaming. Náº¿u production â†’ Hybrid.

**Q: Cáº£ 2 pipelines cÃ³ conflict?**
A: KhÃ´ng, chÃºng independent. Elasticsearch tá»± merge dá»±a trÃªn `link` ID.

**Q: Performance cÃ³ áº£nh hÆ°á»Ÿng?**
A: Minimal. Batch chá»‰ cháº¡y theo lá»‹ch, khÃ´ng áº£nh hÆ°á»Ÿng streaming.

**Q: LÃ m sao Ä‘á»ƒ test?**
A: DÃ¹ng `unified_pipeline.py` Ä‘á»ƒ dá»… dÃ ng switch giá»¯a cÃ¡c modes.
